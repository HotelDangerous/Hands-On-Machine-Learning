{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b3b331",
   "metadata": {},
   "source": [
    "# Classification on the MNIST Dataset\n",
    "## Framing the Problem\n",
    "We are asked to build a model that can distinguish the handwritten digits in the MNIST dataset with an accuraccy of <ins>at least</ins> 97 percent.\n",
    "\n",
    "The task we are trying to accomplish is supervised classification. It is supervised because each instance in the data comes with a label and classification because we are only trying to predict one of ten distinct values.\n",
    "\n",
    "Performance will be measured using accuracy:\n",
    "$$\n",
    "Accuracy = \\frac{number\\ correct\\ predictions}{total\\ number\\ of\\ instances}\n",
    "$$\n",
    "\n",
    "Lastly, we are told that the KNeighborsClassifier seems to work well on the dataset. We are urged to atleast consider this classifier when building our model.\n",
    "## Getting the Data\n",
    "The MNIST dataset is a very famous dataset in machine learning. Due to how often this dataset is used in Machine Learning, Scikit-Learn offers a helper function to get the data- *fetch_openml()*. Let's fetch the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8866a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keenan/.local/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame =False)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e162d610",
   "metadata": {},
   "source": [
    "Datasets loaded by Scikit-Learn often have a dictionary structure with these keys. Unsuprisingly, we are interested in the 'data' and 'target' keys. However, if we did not know much about the data; the 'DESCR' key offers a detailed description about this dataset. Let's save the data and labels as X and y respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca71991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c3afe9",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "Let's explore the data a little bit. It's good to have an understanding of what kind of structures were working with. Perhaps some good things to figure out would be what type does our data come in and what is the size of our data? Before we mess with anything, let's save a copy of both X and y so we don't corrupt the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6013cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our training data and testing data is (70000, 784) and (70000,),respectively.\n"
     ]
    }
   ],
   "source": [
    "X_train_raw, labels = X.copy(), y.copy()\n",
    "\n",
    "print(\"The shape of our training data and testing data is {} and {},\"\n",
    "      \"respectively.\".format(X_train_raw.shape, labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69953c5f",
   "metadata": {},
   "source": [
    "We see that our training data contains 70,000 instances each with 784 features. The 784 features in the MNIST dataset represent one pixel each of the 28 pixel by 28 pixel digital images in the dataset. Let's view a random instance from this dataset, say the 42nd instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac6cad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def instance_to_image(some_number):\n",
    "    some_number_image = some_number.reshape(28, 28)  # reshape array\n",
    "    plt.imshow(some_number_image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "instance_to_image(X_train_raw[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791066af",
   "metadata": {},
   "source": [
    "This looks like a seven. We can verify which number this is by calling labels[42], which returns the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0031ce1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b333d8",
   "metadata": {},
   "source": [
    "We were correct, it is a seven. But we also note that the returned label is a string. We might want to cast this as an integer; most Machine Learning models expect numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7df8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels = labels.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7b116",
   "metadata": {},
   "source": [
    "## Training a Multiclass Classifier\n",
    "Because we are trying to classify each instance as an integer between zero and nine, inclusive, we are dealing with a multiclass classification problem. Before we begin training, we need to make sure that the classifiers we choose can handle multiple classes. The Random Forest, Naive Bayes, and K Nearest Neighbors classifiers can all, natively, handle multiclass classification. Two other classifiers we might be interested in are Stochastic Gradient Descent and Support Vector classifiers, but these distinguish between two classes. Luckily, Scikit-Learn remedies this problem by implementing a one vs. the rest or one vs. one scheme. Hence those classifiers may still be used for multiclass classsification.\n",
    "\n",
    "Let's start by training these classifiers and getting an idea of how they perform by getting the cross_val_scores on the training set.\n",
    "### Creating the Train and Test Sets\n",
    "Before we continue, we need to create the train and test sets. The MNIST dataset has already been shuffled so we don't need to worry about doing it ourselves. It is also classic to take the first 60,000 instances for training and the last 10,000 for testing. We will abide by this tradition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f63cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X_train_raw[:60000], X_train_raw[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a9caa",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Now let's train a few classifiers and see how they perform. We will start by training a Random Forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8c33f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9653, 0.9626, 0.9658])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_clf = RandomForestClassifier()\n",
    "cross_val_score(forest_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b51f10",
   "metadata": {},
   "source": [
    "Wow! The Random Forest Classifier is already achieving very high accuracy scores, above 96 percent with every fold. With some hyperparameter tuning we can surely get this above 97 percent. Before we get too far ahead of ourselves, we should check some other metrics to make sure nothing dubious is going on. Before that though, let's train another classifier.\n",
    "### Naive Bayes\n",
    "We have already found one classifier which shows promise, let's see if the Naive Bayes classifier can produce a similair results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc816006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5592, 0.5603, 0.5572])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "bayes_clf = GaussianNB()\n",
    "cross_val_score(bayes_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37adad65",
   "metadata": {},
   "source": [
    "Oof. The Naive Bayes classifier performed much worse than the Random Forest Classifier. This might be for a number of reasons, but its likely that one of the assumptions that the Naive Bayes classifier makes is invalid for this data. It should be noted though that this is significantly better than random guessing. With random guessing we should expect ten percent accuracy. Let's hope that the K Nearest Neighbor classifier can perform better.\n",
    "### K Nearest Neighbors\n",
    "This is the classifier we we're recommended to try. Let's see if how it performs in our cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e7706c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9676 , 0.9671 , 0.96755])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "cross_val_score(knn_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633792dd",
   "metadata": {},
   "source": [
    "The information we received about the K Nearest Neighbors classifier was good! This is our best classifier yet; just edging out the Random Forest classsifiers.\n",
    "### Support Vector Classifier\n",
    "This is our first classifier that cannot natively perform multiclass classification. We can still use it, however, because Scikit-Learn will implement a one versus one or one versus the rest scheme- *automatically*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72492205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.977 , 0.9738, 0.9739])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "sv_clf = SVC()\n",
    "cross_val_score(sv_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c500f0a",
   "metadata": {},
   "source": [
    "Suprisingly, though Support Vector Classifiers don't natively work on  multiclass classification problems, we have achieved our highest accuracy yet! Not only that but we've already beaten the 97 percent minimum that we required of ourselves.\n",
    "### Stochastic Gradient Descent\n",
    "This is ourr other classifier which does not natively handle multiclass classification. Let's see if it can go toe to toe with the Support Vector classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80050a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88355, 0.87355, 0.8538 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier()\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9245ad",
   "metadata": {},
   "source": [
    "The Stochastic Gradient Descent classifier did do pretty well, but with how strongly some of our other classifiers performed we probably wont spend any time trying to improve this one. Let's move forward and investigate our three best models with some other measures.\n",
    "## Performance Measures\n",
    "So we've found some pretty strong classifiers. We will move forward with the three classifiers that performed the best on our initial cross-validation as measured by aaccuracy:\n",
    "1. Support Vector Classifiier (> 97% accuracy)\n",
    "2. K Nearest Neighbors (> 96 % accuracy\n",
    "3. Random Forest Classifier (> 96% accuracy)\n",
    "\n",
    "Let's try to dive a little deeper and see whats going on with these models, where we might improve, and if any of the models have sticking points or draw backs. One drawback already with our best perfroming classifier is that it takes significantly longer to train. Actually, KNN doesn't really train at all, but thats beside the point.\n",
    "\n",
    "### Precision and Recall\n",
    "Precision is the accuracy of the positive predictions. And Recall is the rate of positive instances detected by the classifier. Precision and recall can be expressed as:\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "where TP, FP, and FN stand for true positive, false positive, and false negative, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa2d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def print_precision_recall(classifier_name, true, predicted):\n",
    "    print(classifier_name.upper())\n",
    "    print(\"PRECISION:\", precision_score(true, predicted, average=\"weighted\"))\n",
    "    print(\"RECALL:\", recall_score(true, predicted, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3f06b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT VECTOR CLASSIFIER\n",
      "PRECISION: 0.9748918993843143\n",
      "RECALL: 0.9749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "svc_predicted = cross_val_predict(sv_clf, X_train, y_train, cv=3)\n",
    "print_precision_recall(\"Support Vector Classifier\", y_train, svc_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a556ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CLASSIFIER\n",
      "PRECISION: 0.9647351828584824\n",
      "RECALL: 0.96475\n"
     ]
    }
   ],
   "source": [
    "forest_predicted = cross_val_predict(forest_clf, X_train, y_train, cv=3)\n",
    "print_precision_recall(\"Random Forest Classifier\", y_train, forest_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f20a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K NEAREST NEIGHBORS\n",
      "PRECISION: 0.9676755320854337\n",
      "RECALL: 0.9674166666666667\n"
     ]
    }
   ],
   "source": [
    "knn_predicted = cross_val_predict(knn_clf, X_train, y_train, cv=3)\n",
    "print_precision_recall(\"K Nearest Neighbors\", y_train, knn_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3267f6",
   "metadata": {},
   "source": [
    "The recall and precision scores tell the same story as the accuracy. K Nearest Neighbors just edges out the Random Forest classifier as the second best classifier and the Support Vector classifier is still performing the best. We could comparee these by plotting a Receiver Operating Characteristic (ROC) curve and then measuring the are under the curve, but all these classifiers are performing so similairly, we wouldn't be able to descern anything from the graph and the areas would be very similair. Instead lets illuustrate a confusion matrix. This will also show us where each classifier is having the most trouble.\n",
    "### Confusion Matrix\n",
    "A confusion matrix will tell us how many times an instance of class x is classified as class y. We might expect a lot of fives and threes to be confused with one another, because these numbers look similair. Note: columns denote the predicted class while rows denote the actual class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44b4be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_confusion_matrix(mx_title, conf_mx):\n",
    "    print(mx_title.upper())\n",
    "    \n",
    "    row_sum = conf_mx.sum(axis=1, keepdims=True)\n",
    "    norm_conf_mx = conf_mx / row_sum\n",
    "    np.fill_diagonal(norm_conf_mx, 0)  # make diagonal black\n",
    "    plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "346b9c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORT VECTOR CLASSIFIER\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K NEAREST NEIGHBORS\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "svc_mat = confusion_matrix(y_train, svc_predicted)\n",
    "knn_mat = confusion_matrix(y_train, knn_predicted)\n",
    "\n",
    "illustrate_confusion_matrix(\"Support Vector Classifier\", svc_mat)\n",
    "illustrate_confusion_matrix(\"K Nearest Neighbors\", knn_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac80ad",
   "metadata": {},
   "source": [
    "It appears that the Support Vector Classifier struggles most with nines and fours. We can understand intuiitively why this might be true. Nines and fours do kind of resemble eachother. It also has problems with nines and sevens, likely for the same reason. Similairly fives and threes. Interestingly it often misclassifies threes as twos but seldom twos for threes. It also seems to have trouble when the true label is eight.\n",
    "\n",
    "K Nearest Neighbors looks much more assymetric. It often predicts a four to be a nine, but often doesn't predict nines to be fours. The only most symmetric parts are confusion about fives and threes. K nearest Neighbors also seems to struggle in classifying eights.\n",
    "\n",
    "Let's do some data manipulation and see if we can further improve these scores.\n",
    "## Data Manipulation and Augmentation\n",
    "Let's start by just standardizing the data. We can do this with Scikiit-Learns Standard Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e916f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbea49d",
   "metadata": {},
   "source": [
    "Now that the data has been standardized, let's test our two classifiers to see if they improve with this manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae110d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9376, 0.9411, 0.9424])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn_clf, X_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2edca",
   "metadata": {},
   "source": [
    "Our K Nearest Neighbor classifier actually performed worse. Let's see if the same is true for the Support Vector classifier. We might need to consider a different data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cc5f3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9596, 0.9602, 0.961 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sv_clf, X_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed7da9",
   "metadata": {},
   "source": [
    "It looks like this manipulation was not good. Its likely because we are attempting to force  our pixel values into a distribution that is not representative of our data. Perhaps a better plan would just be to scale the data down so that it fits on the interval from zero to one. Let's try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea803f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_normalized = normalize(X_train.astype(np.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f7a17",
   "metadata": {},
   "source": [
    "Now that the data has been normalized to fit a zero to one scale, basically all values have been divided by 255 (assuming 255 is the highest pixel intensity in the dataset). Let's see how our models perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e567029b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97255, 0.97015, 0.97185])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn_clf, X_normalized, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f21d6",
   "metadata": {},
   "source": [
    "It appears our data liked this manipulation more. In fact, this is the first time we have reached an average accuracy greater than 97 percent with the K Nearest Neighbors classifier. Let's see how our Support Vector classifier does with this same training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb1bd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97715, 0.9762 , 0.97665])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(sv_clf, X_normalized, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1544969",
   "metadata": {},
   "source": [
    "This normalization of the data does not seem to have hurt or helped our scores. Let's move forward with a more sophisticated data operation.\n",
    "### Data Augmentation\n",
    "Data augmentation is the process of artificially growing the training set by manipulating existing data, then adding the manipulated data to the training set as if it were new data. Here, we will perform data augmentation by taking each image in the dataset, shifting it right, left, up or down by one pixel. Let's right a function to do this.\n",
    "\n",
    "We'll start with a function that shifts the images up one pixel. We can do this by deleting the first 28 elements in the array (the top row of the image), copying the last 28 pixels and then appending them to the array. We copy the last 28 pixels to essentially extend the image by whatever color pixel was at the edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae3497fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image_up(train_set):\n",
    "    for image in train_set:\n",
    "        image = image[28:]\n",
    "        image = np.append(image, image[-28:])\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65b4ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_augmented_up = shift_image_up(X_train.copy())\n",
    "X_augmented = np.append(X_train, X_augmented_up, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c797006",
   "metadata": {},
   "source": [
    "Now, we have doubled the size of our training set, so we also need to make labels for this training set. This eill be easy. Just append the list of labels to itself. We can print the shape of the augmented training set hust to make sure everything went to plan. The shape should be (120000, 784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e258712b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 784)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_augmented = np.append(y_train, y_train)\n",
    "X_augmented.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630ae13",
   "metadata": {},
   "source": [
    "Now, lets train a classifier on this set and see if the accuracy improves. We will use a K Nearest Neighbor classifier. We choose to continue with the KNN classifier because it is only marginally worse, but it runs in a matter of seconds rather than minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "571d07dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9805  , 0.9811  , 0.981375])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn_clf, X_augmented, y_train_augmented, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb58cd7",
   "metadata": {},
   "source": [
    "Look at that, we have achieved our highest accuracy yet. We can see that augmenting our data can be useful. Let's perform one more augmentation, but this time shift everything down by one pixel. And dont forget to update the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b3a490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_image_down(train_set):\n",
    "    for image in train_set:\n",
    "        image = image[:-28]\n",
    "        image = np.append(image[:28], image)\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1465782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 784)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_augmented_down = shift_image_down(X_train.copy())\n",
    "X_augmented = np.append(X_augmented, X_augmented_down, axis=0)\n",
    "\n",
    "y_train_augmented = np.append(y_train_augmented, y_train)\n",
    "\n",
    "X_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16413a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98716667, 0.98716667, 0.98716667])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn_clf, X_augmented, y_train_augmented, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f15a1c",
   "metadata": {},
   "source": [
    "Once again, we have increased our average accuracy. It looks like it might even be possible for us to get to 99 percent accuracy with enough effort. Let's move on to hyperparameter tuning, maybe we can increase our accuracy without adding more data.\n",
    "## Tuning our Model\n",
    "From here forward, we will only be working with the K Nearest Neighbor classifier, this is simply due to its speed. Continuing with the Support Vector classifiers is completely possible, but with limited time and computing power, this option seems better.\n",
    "\n",
    "We will be using Scikit-Learns GridSearchCV tool for tuning the hyperparameters. All we have to do is tell it which hyperparameters we want to tweak and which values we would like to try. The parameters we want to tweak are the weights, algorithm, and leaf_size (when possible) hyperparameters.\n",
    "\n",
    "EDIT: I tried using GridSearchCV to test many hyperparameters, but after running all night it hadn't finished. I then ran about a third of the parameters and got the same result. Now I just want to see if the model performs better with distance weights rather than uniform weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ca0967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98323333, 0.98373333])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_distance_weighted = KNeighborsClassifier(weights = 'distance')\n",
    "cross_val_score(knn_clf, X_augmented, y_train_augmented, cv=2, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab4d13",
   "metadata": {},
   "source": [
    "Now let's see if it performs any better by checking more neighbors. Currently it checks 5 neighbors. Let's double this to ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c3594d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98323333, 0.98373333])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_distance_weighted = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "cross_val_score(knn_clf, X_augmented, y_train_augmented, cv=2, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f7a816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
